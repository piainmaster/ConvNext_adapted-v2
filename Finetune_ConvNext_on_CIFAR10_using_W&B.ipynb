{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Alex16092000/ConvNext_adapted/blob/main/Finetune_ConvNext_on_CIFAR10_using_W%26B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use this notebook to finetune a ConvNeXt-tiny model on CIFAR 10 dataset. The [official ConvNeXt repository](https://github.com/facebookresearch/ConvNeXt) is instrumented with [Weights and Biases](https://wandb.ai/site). You can now easily log your train/test metrics and version control your model checkpoints to Weigths and Biases"
   ],
   "metadata": {
    "id": "LniKjqdogsrH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ⚽️ Installation and Setup\n",
    "\n",
    "The following installation instruction is based on [INSTALL.md](https://github.com/facebookresearch/ConvNeXt/blob/main/INSTALL.md) provided by the official ConvNeXt repository."
   ],
   "metadata": {
    "id": "1JS4ffXFRnRr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -qq torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install -qq wandb timm==0.4.12 six tensorboardX"
   ],
   "metadata": {
    "id": "5YbEGpKrDKC5",
    "outputId": "717aec18-d8a3-4e39-919a-8f3425c16409",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 GB\u001B[0m \u001B[31m1.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m22.3/22.3 MB\u001B[0m \u001B[31m74.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.7/2.7 MB\u001B[0m \u001B[31m103.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.11.0+cu113 which is incompatible.\n",
      "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.11.0+cu113 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m8.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m377.0/377.0 kB\u001B[0m \u001B[31m45.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m101.7/101.7 kB\u001B[0m \u001B[31m16.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m190.6/190.6 kB\u001B[0m \u001B[31m18.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m252.8/252.8 kB\u001B[0m \u001B[31m28.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.7/62.7 kB\u001B[0m \u001B[31m10.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download the official ConvNeXt respository."
   ],
   "metadata": {
    "id": "kDXQ-EpX9fsB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone -b main https://github.com/piainmaster/ConvNext_adapted/ ConvNeXt_finetune\n",
    "!git clone -b pn/ResNeXt-ify https://github.com/piainmaster/ConvNext_adapted/ ConvNeXt_revertResNeXt-ify\n",
    "!git clone -b pn/ResNeXt-ify_depthconv https://github.com/piainmaster/ConvNext_adapted/ ConvNeXt_revertResNeXt-ify_depthconv\n"
   ],
   "metadata": {
    "id": "zmmHO1Cp4E90",
    "outputId": "b4678538-9eae-47b3-b2af-f7d7f434b210",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'ConvNext_adapted'...\n",
      "remote: Enumerating objects: 252, done.\u001B[K\n",
      "remote: Counting objects: 100% (252/252), done.\u001B[K\n",
      "remote: Compressing objects: 100% (99/99), done.\u001B[K\n",
      "remote: Total 252 (delta 132), reused 252 (delta 132), pack-reused 0\u001B[K\n",
      "Receiving objects: 100% (252/252), 66.15 KiB | 1.54 MiB/s, done.\n",
      "Resolving deltas: 100% (132/132), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 🏀 Download the Dataset\n",
    "\n",
    "We will be finetuning on CIFAR-10 dataset. To use any custom dataset (CIFAR-10 here) the format of the dataset should be as shown below:\n",
    "\n",
    "```\n",
    "/path/to/dataset/\n",
    "  train/\n",
    "    class1/\n",
    "      img1.jpeg\n",
    "    class2/\n",
    "      img2.jpeg\n",
    "  val/\n",
    "    class1/\n",
    "      img3.jpeg\n",
    "    class2/\n",
    "      img4.jpeg\n",
    "```\n",
    "\n",
    "I have used this [repository](https://github.com/YoongiKim/CIFAR-10-images) that has the CIFAR-10 images in the required format."
   ],
   "metadata": {
    "id": "yoVwkQ0v80KW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/YoongiKim/CIFAR-10-images"
   ],
   "metadata": {
    "id": "8xcQ6QV41k8S",
    "outputId": "7d969eca-c136-4321-d7a7-f8b38fcc6094",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'CIFAR-10-images'...\n",
      "remote: Enumerating objects: 60027, done.\u001B[K\n",
      "remote: Total 60027 (delta 0), reused 0 (delta 0), pack-reused 60027\u001B[K\n",
      "Receiving objects: 100% (60027/60027), 19.94 MiB | 6.64 MiB/s, done.\n",
      "Resolving deltas: 100% (59990/59990), done.\n",
      "Updating files: 100% (60001/60001), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 🏈 Download Pretrained Weights\n",
    "\n",
    "We will be finetuning the ConvNeXt Tiny model pretrained on ImageNet 1K dataset."
   ],
   "metadata": {
    "id": "J6qUVfL29tH1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%cd ConvNeXt_revertResNeXt-ify_depthconv/\n",
    "!wget https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth"
   ],
   "metadata": {
    "id": "TYPDl5bT8LZ5",
    "outputId": "aab2df0d-fcf7-4366-97b2-c180cba10557",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/ConvNext_adapted\n",
      "--2023-12-06 13:05:31--  https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.162.163.19, 3.162.163.11, 3.162.163.34, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.162.163.19|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 114414741 (109M) [binary/octet-stream]\n",
      "Saving to: ‘convnext_tiny_1k_224_ema.pth’\n",
      "\n",
      "convnext_tiny_1k_22 100%[===================>] 109.11M   190MB/s    in 0.6s    \n",
      "\n",
      "2023-12-06 13:05:31 (190 MB/s) - ‘convnext_tiny_1k_224_ema.pth’ saved [114414741/114414741]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git pull"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 🎾 Train with Weights and Biases\n",
    "\n",
    "If you want to log the train and evaluation metrics using Weights and Biases pass `--enable_wandb true`.\n",
    "\n",
    "You can also save the finetuned checkpoints as version controlled W&B [Artifacts](https://docs.wandb.ai/guides/artifacts) if you pass `--wandb_ckpt true`.\n",
    "\n"
   ],
   "metadata": {
    "id": "pSPgPCjp-Lro"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python main.py --epochs 100 \\\n",
    "                --batch_size 16 \\\n",
    "                --model convnext_tiny \\\n",
    "                --data_set image_folder \\\n",
    "                --data_path ../CIFAR-10-images/train \\\n",
    "                --eval_data_path ../CIFAR-10-images/test \\\n",
    "                --nb_classes 10 \\\n",
    "                --num_workers 8 \\\n",
    "                --warmup_epochs 0 \\\n",
    "                --save_ckpt true \\\n",
    "                --output_dir model_ckpt \\\n",
    "                --finetune convnext_tiny_1k_224_ema.pth \\\n",
    "                --cutmix 0 \\\n",
    "                --mixup 0 --lr 4e-4 \\\n",
    "                --enable_wandb true --wandb_ckpt true"
   ],
   "metadata": {
    "id": "_8sNl2Mb6x8_",
    "outputId": "b65ec736-11eb-49e2-d792-d73630e11f3e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Not using distributed mode\n",
      "Namespace(batch_size=64, epochs=10, update_freq=1, model='convnext_tiny', drop_path=0, input_size=224, layer_scale_init_value=1e-06, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, model_ema_eval=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, weight_decay_end=None, lr=0.0004, layer_decay=1.0, min_lr=1e-06, warmup_epochs=0, warmup_steps=-1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', crop_pct=None, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='convnext_tiny_1k_224_ema.pth', head_init_scale=1.0, model_key='model|module', model_prefix='', data_path='../CIFAR-10-images/train', eval_data_path='../CIFAR-10-images/test', nb_classes=10, imagenet_default_mean_and_std=True, data_set='image_folder', output_dir='model_ckpt', log_dir=None, device='cuda', seed=0, resume='', auto_resume=True, save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, start_epoch=0, eval=False, dist_eval=True, disable_eval=False, num_workers=8, pin_mem=True, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', use_amp=False, enable_wandb=True, project='convnext', wandb_ckpt=True, distributed=False)\n",
      "Transform = \n",
      "RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
      "RandomHorizontalFlip(p=0.5)\n",
      "<timm.data.auto_augment.RandAugment object at 0x78d87934bee0>\n",
      "ToTensor()\n",
      "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      "<timm.data.random_erasing.RandomErasing object at 0x78d87934bd30>\n",
      "---------------------------\n",
      "Number of the class = 10\n",
      "Transform = \n",
      "Resize(size=256, interpolation=bicubic, max_size=None, antialias=None)\n",
      "CenterCrop(size=(224, 224))\n",
      "ToTensor()\n",
      "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      "---------------------------\n",
      "Number of the class = 10\n",
      "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x78d87934b8b0>\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: (1) Create a W&B account\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: (2) Use an existing W&B account\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: (3) Don't visualize my results\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Enter your choice: 2\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You chose 'Use an existing W&B account'\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.16.1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/content/ConvNext_adapted/wandb/run-20231206_130610-0iuii8bt\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33matomic-frog-18\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at \u001B[34m\u001B[4mhttps://wandb.ai/computer__vision/convnext\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run at \u001B[34m\u001B[4mhttps://wandb.ai/computer__vision/convnext/runs/0iuii8bt\u001B[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Load ckpt from convnext_tiny_1k_224_ema.pth\n",
      "Load state_dict by model_key = model\n",
      "Removing key head.weight from pretrained checkpoint\n",
      "Removing key head.bias from pretrained checkpoint\n",
      "Weights of ConvNeXt not initialized from pretrained model: ['head.weight', 'head.bias']\n",
      "Model = ConvNeXt(\n",
      "  (downsample_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Linear(in_features=768, out_features=10, bias=True)\n",
      ")\n",
      "number of params: 27827818\n",
      "LR = 0.00040000\n",
      "Batch size = 64\n",
      "Update frequent = 1\n",
      "Number of training examples = 50000\n",
      "Number of training training per epoch = 781\n",
      "Param groups = {\n",
      "  \"decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"downsample_layers.0.0.weight\",\n",
      "      \"downsample_layers.1.1.weight\",\n",
      "      \"downsample_layers.2.1.weight\",\n",
      "      \"downsample_layers.3.1.weight\",\n",
      "      \"stages.0.0.dwconv.weight\",\n",
      "      \"stages.0.0.pwconv1.weight\",\n",
      "      \"stages.0.0.pwconv2.weight\",\n",
      "      \"stages.0.1.dwconv.weight\",\n",
      "      \"stages.0.1.pwconv1.weight\",\n",
      "      \"stages.0.1.pwconv2.weight\",\n",
      "      \"stages.0.2.dwconv.weight\",\n",
      "      \"stages.0.2.pwconv1.weight\",\n",
      "      \"stages.0.2.pwconv2.weight\",\n",
      "      \"stages.1.0.dwconv.weight\",\n",
      "      \"stages.1.0.pwconv1.weight\",\n",
      "      \"stages.1.0.pwconv2.weight\",\n",
      "      \"stages.1.1.dwconv.weight\",\n",
      "      \"stages.1.1.pwconv1.weight\",\n",
      "      \"stages.1.1.pwconv2.weight\",\n",
      "      \"stages.1.2.dwconv.weight\",\n",
      "      \"stages.1.2.pwconv1.weight\",\n",
      "      \"stages.1.2.pwconv2.weight\",\n",
      "      \"stages.2.0.dwconv.weight\",\n",
      "      \"stages.2.0.pwconv1.weight\",\n",
      "      \"stages.2.0.pwconv2.weight\",\n",
      "      \"stages.2.1.dwconv.weight\",\n",
      "      \"stages.2.1.pwconv1.weight\",\n",
      "      \"stages.2.1.pwconv2.weight\",\n",
      "      \"stages.2.2.dwconv.weight\",\n",
      "      \"stages.2.2.pwconv1.weight\",\n",
      "      \"stages.2.2.pwconv2.weight\",\n",
      "      \"stages.2.3.dwconv.weight\",\n",
      "      \"stages.2.3.pwconv1.weight\",\n",
      "      \"stages.2.3.pwconv2.weight\",\n",
      "      \"stages.2.4.dwconv.weight\",\n",
      "      \"stages.2.4.pwconv1.weight\",\n",
      "      \"stages.2.4.pwconv2.weight\",\n",
      "      \"stages.2.5.dwconv.weight\",\n",
      "      \"stages.2.5.pwconv1.weight\",\n",
      "      \"stages.2.5.pwconv2.weight\",\n",
      "      \"stages.2.6.dwconv.weight\",\n",
      "      \"stages.2.6.pwconv1.weight\",\n",
      "      \"stages.2.6.pwconv2.weight\",\n",
      "      \"stages.2.7.dwconv.weight\",\n",
      "      \"stages.2.7.pwconv1.weight\",\n",
      "      \"stages.2.7.pwconv2.weight\",\n",
      "      \"stages.2.8.dwconv.weight\",\n",
      "      \"stages.2.8.pwconv1.weight\",\n",
      "      \"stages.2.8.pwconv2.weight\",\n",
      "      \"stages.3.0.dwconv.weight\",\n",
      "      \"stages.3.0.pwconv1.weight\",\n",
      "      \"stages.3.0.pwconv2.weight\",\n",
      "      \"stages.3.1.dwconv.weight\",\n",
      "      \"stages.3.1.pwconv1.weight\",\n",
      "      \"stages.3.1.pwconv2.weight\",\n",
      "      \"stages.3.2.dwconv.weight\",\n",
      "      \"stages.3.2.pwconv1.weight\",\n",
      "      \"stages.3.2.pwconv2.weight\",\n",
      "      \"head.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  },\n",
      "  \"no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"downsample_layers.0.0.bias\",\n",
      "      \"downsample_layers.0.1.weight\",\n",
      "      \"downsample_layers.0.1.bias\",\n",
      "      \"downsample_layers.1.0.weight\",\n",
      "      \"downsample_layers.1.0.bias\",\n",
      "      \"downsample_layers.1.1.bias\",\n",
      "      \"downsample_layers.2.0.weight\",\n",
      "      \"downsample_layers.2.0.bias\",\n",
      "      \"downsample_layers.2.1.bias\",\n",
      "      \"downsample_layers.3.0.weight\",\n",
      "      \"downsample_layers.3.0.bias\",\n",
      "      \"downsample_layers.3.1.bias\",\n",
      "      \"stages.0.0.gamma\",\n",
      "      \"stages.0.0.dwconv.bias\",\n",
      "      \"stages.0.0.norm.weight\",\n",
      "      \"stages.0.0.norm.bias\",\n",
      "      \"stages.0.0.pwconv1.bias\",\n",
      "      \"stages.0.0.pwconv2.bias\",\n",
      "      \"stages.0.1.gamma\",\n",
      "      \"stages.0.1.dwconv.bias\",\n",
      "      \"stages.0.1.norm.weight\",\n",
      "      \"stages.0.1.norm.bias\",\n",
      "      \"stages.0.1.pwconv1.bias\",\n",
      "      \"stages.0.1.pwconv2.bias\",\n",
      "      \"stages.0.2.gamma\",\n",
      "      \"stages.0.2.dwconv.bias\",\n",
      "      \"stages.0.2.norm.weight\",\n",
      "      \"stages.0.2.norm.bias\",\n",
      "      \"stages.0.2.pwconv1.bias\",\n",
      "      \"stages.0.2.pwconv2.bias\",\n",
      "      \"stages.1.0.gamma\",\n",
      "      \"stages.1.0.dwconv.bias\",\n",
      "      \"stages.1.0.norm.weight\",\n",
      "      \"stages.1.0.norm.bias\",\n",
      "      \"stages.1.0.pwconv1.bias\",\n",
      "      \"stages.1.0.pwconv2.bias\",\n",
      "      \"stages.1.1.gamma\",\n",
      "      \"stages.1.1.dwconv.bias\",\n",
      "      \"stages.1.1.norm.weight\",\n",
      "      \"stages.1.1.norm.bias\",\n",
      "      \"stages.1.1.pwconv1.bias\",\n",
      "      \"stages.1.1.pwconv2.bias\",\n",
      "      \"stages.1.2.gamma\",\n",
      "      \"stages.1.2.dwconv.bias\",\n",
      "      \"stages.1.2.norm.weight\",\n",
      "      \"stages.1.2.norm.bias\",\n",
      "      \"stages.1.2.pwconv1.bias\",\n",
      "      \"stages.1.2.pwconv2.bias\",\n",
      "      \"stages.2.0.gamma\",\n",
      "      \"stages.2.0.dwconv.bias\",\n",
      "      \"stages.2.0.norm.weight\",\n",
      "      \"stages.2.0.norm.bias\",\n",
      "      \"stages.2.0.pwconv1.bias\",\n",
      "      \"stages.2.0.pwconv2.bias\",\n",
      "      \"stages.2.1.gamma\",\n",
      "      \"stages.2.1.dwconv.bias\",\n",
      "      \"stages.2.1.norm.weight\",\n",
      "      \"stages.2.1.norm.bias\",\n",
      "      \"stages.2.1.pwconv1.bias\",\n",
      "      \"stages.2.1.pwconv2.bias\",\n",
      "      \"stages.2.2.gamma\",\n",
      "      \"stages.2.2.dwconv.bias\",\n",
      "      \"stages.2.2.norm.weight\",\n",
      "      \"stages.2.2.norm.bias\",\n",
      "      \"stages.2.2.pwconv1.bias\",\n",
      "      \"stages.2.2.pwconv2.bias\",\n",
      "      \"stages.2.3.gamma\",\n",
      "      \"stages.2.3.dwconv.bias\",\n",
      "      \"stages.2.3.norm.weight\",\n",
      "      \"stages.2.3.norm.bias\",\n",
      "      \"stages.2.3.pwconv1.bias\",\n",
      "      \"stages.2.3.pwconv2.bias\",\n",
      "      \"stages.2.4.gamma\",\n",
      "      \"stages.2.4.dwconv.bias\",\n",
      "      \"stages.2.4.norm.weight\",\n",
      "      \"stages.2.4.norm.bias\",\n",
      "      \"stages.2.4.pwconv1.bias\",\n",
      "      \"stages.2.4.pwconv2.bias\",\n",
      "      \"stages.2.5.gamma\",\n",
      "      \"stages.2.5.dwconv.bias\",\n",
      "      \"stages.2.5.norm.weight\",\n",
      "      \"stages.2.5.norm.bias\",\n",
      "      \"stages.2.5.pwconv1.bias\",\n",
      "      \"stages.2.5.pwconv2.bias\",\n",
      "      \"stages.2.6.gamma\",\n",
      "      \"stages.2.6.dwconv.bias\",\n",
      "      \"stages.2.6.norm.weight\",\n",
      "      \"stages.2.6.norm.bias\",\n",
      "      \"stages.2.6.pwconv1.bias\",\n",
      "      \"stages.2.6.pwconv2.bias\",\n",
      "      \"stages.2.7.gamma\",\n",
      "      \"stages.2.7.dwconv.bias\",\n",
      "      \"stages.2.7.norm.weight\",\n",
      "      \"stages.2.7.norm.bias\",\n",
      "      \"stages.2.7.pwconv1.bias\",\n",
      "      \"stages.2.7.pwconv2.bias\",\n",
      "      \"stages.2.8.gamma\",\n",
      "      \"stages.2.8.dwconv.bias\",\n",
      "      \"stages.2.8.norm.weight\",\n",
      "      \"stages.2.8.norm.bias\",\n",
      "      \"stages.2.8.pwconv1.bias\",\n",
      "      \"stages.2.8.pwconv2.bias\",\n",
      "      \"stages.3.0.gamma\",\n",
      "      \"stages.3.0.dwconv.bias\",\n",
      "      \"stages.3.0.norm.weight\",\n",
      "      \"stages.3.0.norm.bias\",\n",
      "      \"stages.3.0.pwconv1.bias\",\n",
      "      \"stages.3.0.pwconv2.bias\",\n",
      "      \"stages.3.1.gamma\",\n",
      "      \"stages.3.1.dwconv.bias\",\n",
      "      \"stages.3.1.norm.weight\",\n",
      "      \"stages.3.1.norm.bias\",\n",
      "      \"stages.3.1.pwconv1.bias\",\n",
      "      \"stages.3.1.pwconv2.bias\",\n",
      "      \"stages.3.2.gamma\",\n",
      "      \"stages.3.2.dwconv.bias\",\n",
      "      \"stages.3.2.norm.weight\",\n",
      "      \"stages.3.2.norm.bias\",\n",
      "      \"stages.3.2.pwconv1.bias\",\n",
      "      \"stages.3.2.pwconv2.bias\",\n",
      "      \"norm.weight\",\n",
      "      \"norm.bias\",\n",
      "      \"head.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  }\n",
      "}\n",
      "Use Cosine LR scheduler\n",
      "Set warmup steps = 0\n",
      "Set warmup steps = 0\n",
      "Max WD = 0.0500000, Min WD = 0.0500000\n",
      "criterion = LabelSmoothingCrossEntropy()\n",
      "Auto resume checkpoint: \n",
      "Start training for 10 epochs\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:423: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:423: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:423: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:423: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:423: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:423: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:423: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:423: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "Epoch: [0]  [  0/781]  eta: 1:29:19  lr: 0.000400  min_lr: 0.000400  loss: 2.3024 (2.3024)  class_acc: 0.1250 (0.1250)  weight_decay: 0.0500 (0.0500)  time: 6.8624  data: 3.9824  max mem: 8477\n",
      "Epoch: [0]  [ 10/781]  eta: 0:17:23  lr: 0.000400  min_lr: 0.000400  loss: 2.1875 (2.1590)  class_acc: 0.2656 (0.2599)  weight_decay: 0.0500 (0.0500)  time: 1.3535  data: 0.3622  max mem: 8477\n",
      "Epoch: [0]  [ 20/781]  eta: 0:13:53  lr: 0.000400  min_lr: 0.000400  loss: 1.8995 (1.9951)  class_acc: 0.3750 (0.3490)  weight_decay: 0.0500 (0.0500)  time: 0.8071  data: 0.0006  max mem: 8477\n",
      "Epoch: [0]  [ 30/781]  eta: 0:12:36  lr: 0.000400  min_lr: 0.000400  loss: 1.7330 (1.8769)  class_acc: 0.4688 (0.4032)  weight_decay: 0.0500 (0.0500)  time: 0.8165  data: 0.0015  max mem: 8477\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x78d87faa6dd0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1303, in _shutdown_workers\n",
      "    self._worker_result_queue.put((None, None))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 94, in put\n",
      "    self._start_thread()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 177, in _start_thread\n",
      "    self._thread.start()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 940, in start\n",
      "    self._started.wait()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 607, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 320, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt: \n",
      "Traceback (most recent call last):\n",
      "  File \"/content/ConvNext_adapted/main.py\", line 477, in <module>\n",
      "    main(args)\n",
      "  File \"/content/ConvNext_adapted/main.py\", line 402, in main\n",
      "    train_stats = train_one_epoch(\n",
      "  File \"/content/ConvNext_adapted/engine.py\", line 80, in train_one_epoch\n",
      "    optimizer.step()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\", line 145, in step\n",
      "    F.adamw(params_with_grad,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/_functional.py\", line 144, in adamw\n",
      "    exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n",
      "KeyboardInterrupt\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run history:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Rank-0 Batch Wise/global_train_step ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   Rank-0 Batch Wise/train_class_acc ▁▂▂▃▃▂▃▄▅▅▃▅▇▅▅▆▅▇▆▆▆▅▆█▇▆▆██▆█▇▅\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        Rank-0 Batch Wise/train_loss ███▇▇▇▇▆▆▅▆▅▄▅▅▄▄▃▄▄▄▄▃▂▃▃▃▂▂▃▁▂▃\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      Rank-0 Batch Wise/train_max_lr █████████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▃▃▃▂▂▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      Rank-0 Batch Wise/train_min_lr █████████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▃▃▃▂▂▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run summary:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Rank-0 Batch Wise/global_train_step 32\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   Rank-0 Batch Wise/train_class_acc 0.42188\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        Rank-0 Batch Wise/train_loss 1.71866\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      Rank-0 Batch Wise/train_max_lr 0.0004\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      Rank-0 Batch Wise/train_min_lr 0.0004\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run \u001B[33matomic-frog-18\u001B[0m at: \u001B[34m\u001B[4mhttps://wandb.ai/computer__vision/convnext/runs/0iuii8bt\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ️⚡ View job at \u001B[34m\u001B[4mhttps://wandb.ai/computer__vision/convnext/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMTMzNjgxNA==/version_details/v0\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Find logs at: \u001B[35m\u001B[1m./wandb/run-20231206_130610-0iuii8bt/logs\u001B[0m\n",
      "Exception in thread NetStatThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "Exception in thread IntMsgThr:\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 268, in check_network_status\n",
      "    self._loop_check_status(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n",
      "    local_handle = request()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\", line 756, in deliver_network_status\n",
      "    return self._deliver_network_status(status)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 484, in _deliver_network_status\n",
      "    return self._deliver_record(record)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 437, in _deliver_record\n",
      "    handle = mailbox._deliver_record(record, interface=self)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
      "    interface._publish(record)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 300, in check_internal_messages\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    self._loop_check_status(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "    local_handle = request()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\", line 764, in deliver_internal_messages\n",
      "    return self._deliver_internal_messages(internal_message)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 490, in _deliver_internal_messages\n",
      "    return self._deliver_record(record)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 437, in _deliver_record\n",
      "    handle = mailbox._deliver_record(record, interface=self)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
      "    interface._publish(record)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "^C\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 🏐 Conclusion\n",
    "\n",
    "* **The above setting gives a top-1 accuracy of ~95%.**\n",
    "* The ConvNeXt repository comes with modern training regimes and is easy to finetune on any dataset.\n",
    "* The finetune model achieves competitive results.\n",
    "\n",
    "* By passing two arguments you get the following:\n",
    "\n",
    "  * Repository of all your experiments (train and test metrics) as a [W&B Project](https://docs.wandb.ai/ref/app/pages/project-page). You can easily compare experiments to find the best performing model.\n",
    "  * Hyperparameters (Configs) used to train individual models.\n",
    "  * System (CPU/GPU/Disk) metrics.\n",
    "  * Model checkpoints saved as W&B Artifacts. They are versioned and easy to share.\n",
    "\n",
    "  Check out the associated [W&B run page](https://wandb.ai/ayut/convnext/runs/16vi9e31). $→$"
   ],
   "metadata": {
    "id": "350MmZgtBVWy"
   }
  }
 ]
}
